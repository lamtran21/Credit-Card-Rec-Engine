# ğŸ’³ Card Matcher: AI-Powered Credit Card Recommender

An end-to-end project that scrapes real credit card data, stores it in a local database, and uses OpenAIâ€™s GPT to recommend cards based on user input. Built with:

- ğŸ”§ FastAPI for the backend API
- ğŸ’¬ Streamlit for a chatbot-style interface
- ğŸ—ƒ SQLite for data storage
- ğŸ§  OpenAI for recommendation logic
- â˜ï¸ Deployed on Render (API) + Streamlit Cloud (frontend)

---

## ğŸŒŸ Features

- User enters their credit card preferences (e.g. *"I want a student card with no annual fee"*)
- Streamlit frontend sends input to FastAPI backend
- Backend:
  - Loads all cards from a local SQLite database
  - Sends them along with the userâ€™s needs to OpenAI GPT
  - Returns top 3 card matches with concise reasoning based on bonus offer, rewards, APR, annual fee (last scraped July 2025)
- Frontend displays the results like a chatbot

---

## ğŸš€ Live Demo

ğŸ”— **Frontend (Streamlit)**: [https://credit-card-rec-engine.streamlit.app/]

---

## ğŸ“ Project Structure

ğŸ“ card-matcher/
â”œâ”€â”€ api.py                 # FastAPI backend
â”œâ”€â”€ streamlit.py           # Streamlit chatbot frontend
â”œâ”€â”€ llm_card_matcher.py    # Core logic: fetch cards + build OpenAI prompt
â”œâ”€â”€ load_to_db.py          # Load scraped data into SQLite
â”œâ”€â”€ cards.db               # SQLite database of credit card info
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ runtime.txt            # Python version for deployment
â”œâ”€â”€ .python-version        # Local Python version (e.g. pyenv)
â”œâ”€â”€ .gitignore             # Ignores .env, .db, etc.
â””â”€â”€ scrapers/              # Web scrapers for each issuer
    â”œâ”€â”€ scraper_amex.py
    â”œâ”€â”€ scraper_chase.py
    â””â”€â”€ scraper_citi.py

---

## ğŸ“¦ Tech Stack

| Layer        | Tech                |
|--------------|---------------------|
| ğŸ§  AI         | OpenAI GPT-3.5      |
| ğŸ”™ Backend    | FastAPI, Uvicorn    |
| ğŸ’¬ Frontend   | Streamlit           |
| ğŸ—ƒ Database   | SQLite              |
| ğŸŒ Web Scraping | `requests`, `BeautifulSoup`, `Selenium` |
| â˜ï¸ Deployment | Render, Streamlit Cloud |
| ğŸ” Secrets    | `.env` + `python-dotenv` |

---

## ğŸ§ª Example Prompt

> "Iâ€™m looking for a card that earns airline miles with no foreign transaction fee"

Output (from OpenAI via backend):
- Card 1: [name] â€“ Best for frequent flyers with no international fees
- Card 2: [name] â€“ Solid travel rewards and signup bonus
- Card 3: [name] â€“ No annual fee, good for beginners

---

## ğŸ›  How to Run Locally

### 1. Clone and Set Up

```bash
git clone https://github.com/lamtran21/Credit-Card-Rec-Engine.git
cd card-matcher
python -m venv venv
venv\Scripts\activate  # On Windows
pip install -r requirements.txt
```

### 2. Add your OpenAI API key

Create a `.env` file in the root folder:

```
OPENAI_API_KEY=your-api-key-here
```

### 3. Run the backend (FastAPI)

```bash
uvicorn api:app --reload
```

### 4. Run the frontend (Streamlit)

```bash
streamlit run streamlit.py
```

---

## ğŸ“Š Scrapers

To update the card database:

1. Run each scraper inside the `scrapers/` folder (e.g. `scraper_chase.py`)  
2. Then run `load_to_db.py` to populate `cards.db` with fresh data

---

## ğŸ” Environment Variables

- `.env` is used for storing OpenAI key.
- It is **not committed to GitHub** (included in `.gitignore`).

---

## ğŸ“Œ Deployment

- **Backend** is deployed to Render (`api.py`, `cards.db`, and related files)
- **Frontend** is deployed to Streamlit Cloud (`streamlit.py`)
- Deployment uses:
  - `requirements.txt` for dependencies
  - `runtime.txt` to specify Python version (e.g., `python-3.11`)

---

## âœï¸ Author

**Lam Tran**  
ğŸ“ Data Science | Python  
ğŸ”— [LinkedIn](linkedin.com/in/lam-tran21/)

---

## ğŸ“„ License

MIT License â€“ Free to use, modify, and distribute.
